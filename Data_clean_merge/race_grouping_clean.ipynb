{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericr\\AppData\\Local\\Temp\\ipykernel_36620\\1614234590.py:5: DtypeWarning: Columns (15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ela_2018 = pd.read_csv(\n",
      "C:\\Users\\ericr\\AppData\\Local\\Temp\\ipykernel_36620\\1614234590.py:8: DtypeWarning: Columns (15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  math_2018 = pd.read_csv(\n",
      "C:\\Users\\ericr\\AppData\\Local\\Temp\\ipykernel_36620\\1614234590.py:11: DtypeWarning: Columns (15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  science_2018 = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Reading files\n",
    "\n",
    "# Read in the data\n",
    "# 2018\n",
    "ela_2018 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2018\\Annual EM ELA.csv\"\n",
    ")\n",
    "math_2018 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2018\\Annual EM Math.csv\"\n",
    ")\n",
    "science_2018 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2018\\Annual EM SCIENCE.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 654694 entries, 0 to 654693\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   ENTITY_CD           654694 non-null  int64 \n",
      " 1   ENTITY_NAME         654694 non-null  object\n",
      " 2   YEAR                654694 non-null  int64 \n",
      " 3   ASSESSMENT_NAME     654694 non-null  object\n",
      " 4   SUBGROUP_NAME       654694 non-null  object\n",
      " 5   NUM_TESTED          654694 non-null  int64 \n",
      " 6   NOT_TESTED          654694 non-null  int64 \n",
      " 7   LEVEL1_COUNT        654694 non-null  object\n",
      " 8   LEVEL1_%TESTED      654694 non-null  object\n",
      " 9   LEVEL2_COUNT        654694 non-null  object\n",
      " 10  LEVEL2_%TESTED      654694 non-null  object\n",
      " 11  LEVEL3_COUNT        654694 non-null  object\n",
      " 12  LEVEL3_%TESTED      654694 non-null  object\n",
      " 13  LEVEL4_COUNT        654694 non-null  object\n",
      " 14  LEVEL4_%TESTED      654694 non-null  object\n",
      " 15  LEVEL5_COUNT        304561 non-null  object\n",
      " 16  LEVEL5_%TESTED      304561 non-null  object\n",
      " 17  NUM_PROF            304561 non-null  object\n",
      " 18  PER_PROF            304561 non-null  object\n",
      " 19  TOTAL_SCALE_SCORES  654694 non-null  object\n",
      " 20  MEAN_SCORE          620662 non-null  object\n",
      "dtypes: int64(4), object(17)\n",
      "memory usage: 104.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking types\n",
    "ela_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our columns of interest\n",
    "Team_9_keep_cols = [\"NUM_TESTED\", \"NUM_PROF\", \"TOTAL_SCALE_SCORES\", \"MEAN_SCORE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hispanic or Latino', 'Homeless', 'Male',\n",
       "       'Non-English Language Learners', 'Not Economically Disadvantaged',\n",
       "       'American Indian or Alaska Native',\n",
       "       'Asian or Native Hawaiian/Other Pacific Islander',\n",
       "       'Black or African American', 'Economically Disadvantaged',\n",
       "       'English Language Learners', 'Female', 'General Education',\n",
       "       'Multiracial', 'All Students', 'Not Migrant',\n",
       "       'Students with Disabilities', 'White', 'Migrant',\n",
       "       'Small Group Total', 'American Indian or Alaska Native Female',\n",
       "       'American Indian or Alaska Native Male',\n",
       "       'Asian or Native Hawaiian/Other Pacific Islander Female',\n",
       "       'Asian or Native Hawaiian/Other Pacific Islander Male',\n",
       "       'Black or African American Female',\n",
       "       'Black or African American Male', 'Hispanic or Latino Female',\n",
       "       'Hispanic or Latino Male', 'Multiracial Female',\n",
       "       'Multiracial Male', 'White Female', 'White Male', 'Not Homeless',\n",
       "       'Not in Foster Care', 'Parent in Armed Forces',\n",
       "       'Parent Not in Armed Forces', 'In Foster Care'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scouting racial groups\n",
    "ela_2018.SUBGROUP_NAME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sanity_check_entity_cd(ds):\n",
    "    \n",
    "    for i in ds.ENTITY_CD.unique():\n",
    "        try: \n",
    "            int(i)\n",
    "        except:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_df_maker(df : pd.DataFrame, base_cols : list[str], subgroups : list[str], keep_cols : list[str] = []) -> pd.DataFrame:\n",
    "    \"\"\"Takes a our base dataframe and stacks the subgroups horizontally\n",
    "    via a merge.\n",
    "    \"\"\"\n",
    "\n",
    "    copy_df = df.copy() # to contain all the core records\n",
    "\n",
    "    copy_df['Subject'] = copy_df['ASSESSMENT_NAME'].str.extract(r\"([A-Za-z]*).*\", expand=False)\n",
    "\n",
    "    copy_df[copy_df.MEAN_SCORE == 's'] = np.nan\n",
    "\n",
    "    copy_df['MEAN_SCORE'] = copy_df['MEAN_SCORE'].astype(float)\n",
    "\n",
    "    copy_df[\"MEAN_SCORE\"].fillna(copy_df.groupby([\"YEAR\", \"ENTITY_CD\", \"Subject\"])[\"MEAN_SCORE\"].transform(\"mean\"), inplace=True)\n",
    "\n",
    "    base_cols.append(\"Subject\")\n",
    "    \n",
    "    if keep_cols != []:\n",
    "        new_cols = keep_cols + base_cols + [\"SUBGROUP_NAME\"]\n",
    "\n",
    "    else:\n",
    "\n",
    "        new_cols = base_cols + [\"SUBGROUP_NAME\"]\n",
    "\n",
    "    base_df = copy_df[new_cols].copy() # get the core records\n",
    "\n",
    "    base_df.drop_duplicates(subset = base_cols, inplace=True, ignore_index=True) # remove duplicates\n",
    "\n",
    "    core_df = copy_df[new_cols].copy() # get the core records\n",
    "\n",
    "    # At this point, we have a df custom to merge with Team 9's base data\n",
    "    # that contains all the schools,\n",
    "    # But we still need the data by race\n",
    "\n",
    "    # We will create a dictionary of dataframes\n",
    "\n",
    "    for group in subgroups:\n",
    "\n",
    "        # copy to avoid pointer issues\n",
    "        \n",
    "        group_df = core_df[core_df[\"SUBGROUP_NAME\"] == group].copy()\n",
    "\n",
    "        formatted_name = group.replace(\" \", \"_\").lower()\n",
    "\n",
    "        base_df = base_df.merge(group_df, on=base_cols, how=\"left\", suffixes=(\"\", f\"_{formatted_name}\"))\n",
    "\n",
    "    # Removing the subgroup name columns\n",
    "\n",
    "    ls_subgroup_cols = [col for col in base_df.columns if \"subgroup_name\" in col.lower()]\n",
    "\n",
    "    extra_cols = ['NUM_TESTED', 'NUM_PROF', 'TOTAL_SCALE_SCORES', 'MEAN_SCORE']\n",
    "\n",
    "    base_df.drop(columns=ls_subgroup_cols + extra_cols, inplace=True)\n",
    "    \n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENTITY_CD', 'YEAR', 'ASSESSMENT_NAME', 'Subject',\n",
       "       'NUM_TESTED_hispanic_or_latino', 'NUM_PROF_hispanic_or_latino',\n",
       "       'TOTAL_SCALE_SCORES_hispanic_or_latino',\n",
       "       'MEAN_SCORE_hispanic_or_latino', 'NUM_TESTED_black_or_african_american',\n",
       "       'NUM_PROF_black_or_african_american',\n",
       "       'TOTAL_SCALE_SCORES_black_or_african_american',\n",
       "       'MEAN_SCORE_black_or_african_american',\n",
       "       'NUM_TESTED_american_indian_or_alaska_native',\n",
       "       'NUM_PROF_american_indian_or_alaska_native',\n",
       "       'TOTAL_SCALE_SCORES_american_indian_or_alaska_native',\n",
       "       'MEAN_SCORE_american_indian_or_alaska_native',\n",
       "       'NUM_TESTED_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'NUM_PROF_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'NUM_TESTED_multiracial', 'NUM_PROF_multiracial',\n",
       "       'TOTAL_SCALE_SCORES_multiracial', 'MEAN_SCORE_multiracial',\n",
       "       'NUM_TESTED_white', 'NUM_PROF_white', 'TOTAL_SCALE_SCORES_white',\n",
       "       'MEAN_SCORE_white'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function\n",
    "race_df_maker(\n",
    "    ela_2018,\n",
    "    [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "    [\n",
    "        \"Hispanic or Latino\",\n",
    "        \"Black or African American\",\n",
    "        \"American Indian or Alaska Native\",\n",
    "        \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "        \"Multiracial\",\n",
    "        \"White\",\n",
    "    ], keep_cols=Team_9_keep_cols\n",
    ").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36740, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df_maker(\n",
    "    ela_2018,\n",
    "    [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "    [\n",
    "        \"Hispanic or Latino\",\n",
    "        \"Black or African American\",\n",
    "        \"American Indian or Alaska Native\",\n",
    "        \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "        \"Multiracial\",\n",
    "        \"White\",\n",
    "    ], keep_cols=Team_9_keep_cols\n",
    ").shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the function\n",
    "for ds in [ela_2018, math_2018, science_2018]:\n",
    "    sanity_check_entity_cd(ds)\n",
    "    try: \n",
    "        race_df_maker(\n",
    "            ds,\n",
    "            [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "            [\n",
    "                \"Hispanic or Latino\",\n",
    "                \"Black or African American\",\n",
    "                \"American Indian or Alaska Native\",\n",
    "                \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "                \"Multiracial\",\n",
    "                \"White\",\n",
    "            ], keep_cols=Team_9_keep_cols\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(ds.head())\n",
    "        print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds = None\n",
    "\n",
    "for ds in [ela_2018, math_2018, science_2018]:\n",
    "\n",
    "    assert 2018 in ds.YEAR.unique()\n",
    "    \n",
    "    new_ds = race_df_maker(\n",
    "        ds,\n",
    "        [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"],  # ENTITY_NAME\n",
    "        [\n",
    "            \"Hispanic or Latino\",\n",
    "            \"Black or African American\",\n",
    "            \"American Indian or Alaska Native\",\n",
    "            \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "            \"Multiracial\",\n",
    "            \"White\",\n",
    "        ],\n",
    "        keep_cols=Team_9_keep_cols,\n",
    "    )\n",
    "\n",
    "    if final_ds is None:\n",
    "\n",
    "        final_ds = new_ds.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        final_ds = pd.concat([final_ds, new_ds], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final_ds: (96178, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sanity checks\n",
    "\n",
    "print(\"Shape of final_ds:\", final_ds.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY_CD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ASSESSMENT_NAME</th>\n",
       "      <th>Subject</th>\n",
       "      <th>NUM_TESTED_hispanic_or_latino</th>\n",
       "      <th>NUM_PROF_hispanic_or_latino</th>\n",
       "      <th>TOTAL_SCALE_SCORES_hispanic_or_latino</th>\n",
       "      <th>MEAN_SCORE_hispanic_or_latino</th>\n",
       "      <th>NUM_TESTED_black_or_african_american</th>\n",
       "      <th>NUM_PROF_black_or_african_american</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>NUM_TESTED_multiracial</th>\n",
       "      <th>NUM_PROF_multiracial</th>\n",
       "      <th>TOTAL_SCALE_SCORES_multiracial</th>\n",
       "      <th>MEAN_SCORE_multiracial</th>\n",
       "      <th>NUM_TESTED_white</th>\n",
       "      <th>NUM_PROF_white</th>\n",
       "      <th>TOTAL_SCALE_SCORES_white</th>\n",
       "      <th>MEAN_SCORE_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA8</td>\n",
       "      <td>ELA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7</td>\n",
       "      <td>22910</td>\n",
       "      <td>587.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA7</td>\n",
       "      <td>ELA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6</td>\n",
       "      <td>21346</td>\n",
       "      <td>593.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA6</td>\n",
       "      <td>ELA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15</td>\n",
       "      <td>21466</td>\n",
       "      <td>596.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA8</td>\n",
       "      <td>ELA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>14345</td>\n",
       "      <td>598.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA7</td>\n",
       "      <td>ELA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.314000e+11</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA6</td>\n",
       "      <td>ELA</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6</td>\n",
       "      <td>13595</td>\n",
       "      <td>591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ELA3</td>\n",
       "      <td>ELA</td>\n",
       "      <td>28638.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8572251</td>\n",
       "      <td>299.0</td>\n",
       "      <td>14688.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3968338</td>\n",
       "      <td>323.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279413</td>\n",
       "      <td>330.0</td>\n",
       "      <td>11234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3642798</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA5</td>\n",
       "      <td>ELA</td>\n",
       "      <td>28234.0</td>\n",
       "      <td>7670</td>\n",
       "      <td>16817855</td>\n",
       "      <td>596.0</td>\n",
       "      <td>14811.0</td>\n",
       "      <td>3749</td>\n",
       "      <td>...</td>\n",
       "      <td>7783323</td>\n",
       "      <td>610.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>509</td>\n",
       "      <td>494431</td>\n",
       "      <td>613.0</td>\n",
       "      <td>11063.0</td>\n",
       "      <td>6383</td>\n",
       "      <td>6745329</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>ELA3_8</td>\n",
       "      <td>ELA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ENTITY_CD    YEAR ASSESSMENT_NAME Subject   \n",
       "0  3.314000e+11  2018.0            ELA8     ELA  \\\n",
       "1  3.314000e+11  2018.0            ELA7     ELA   \n",
       "2  3.314000e+11  2018.0            ELA6     ELA   \n",
       "3           NaN     NaN             NaN     NaN   \n",
       "4  3.314000e+11  2018.0            ELA8     ELA   \n",
       "5  3.314000e+11  2018.0            ELA7     ELA   \n",
       "6  3.314000e+11  2018.0            ELA6     ELA   \n",
       "7  1.000000e+00  2017.0            ELA3     ELA   \n",
       "8  1.000000e+00  2018.0            ELA5     ELA   \n",
       "9  1.000000e+00  2018.0          ELA3_8     ELA   \n",
       "\n",
       "   NUM_TESTED_hispanic_or_latino NUM_PROF_hispanic_or_latino   \n",
       "0                           39.0                           7  \\\n",
       "1                           36.0                           6   \n",
       "2                           36.0                          15   \n",
       "3                            NaN                         NaN   \n",
       "4                           24.0                          10   \n",
       "5                            NaN                         NaN   \n",
       "6                           23.0                           6   \n",
       "7                        28638.0                         NaN   \n",
       "8                        28234.0                        7670   \n",
       "9                            NaN                         NaN   \n",
       "\n",
       "  TOTAL_SCALE_SCORES_hispanic_or_latino  MEAN_SCORE_hispanic_or_latino   \n",
       "0                                 22910                          587.0  \\\n",
       "1                                 21346                          593.0   \n",
       "2                                 21466                          596.0   \n",
       "3                                   NaN                            NaN   \n",
       "4                                 14345                          598.0   \n",
       "5                                   NaN                            NaN   \n",
       "6                                 13595                          591.0   \n",
       "7                               8572251                          299.0   \n",
       "8                              16817855                          596.0   \n",
       "9                                   NaN                            NaN   \n",
       "\n",
       "   NUM_TESTED_black_or_african_american NUM_PROF_black_or_african_american   \n",
       "0                                   NaN                                NaN  \\\n",
       "1                                   NaN                                NaN   \n",
       "2                                  12.0                                  2   \n",
       "3                                   NaN                                NaN   \n",
       "4                                  14.0                                  6   \n",
       "5                                  24.0                                 13   \n",
       "6                                   NaN                                NaN   \n",
       "7                               14688.0                                NaN   \n",
       "8                               14811.0                               3749   \n",
       "9                                   NaN                                NaN   \n",
       "\n",
       "   ... TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander   \n",
       "0  ...                                                NaN                  \\\n",
       "1  ...                                                NaN                   \n",
       "2  ...                                                NaN                   \n",
       "3  ...                                                NaN                   \n",
       "4  ...                                                NaN                   \n",
       "5  ...                                                NaN                   \n",
       "6  ...                                                NaN                   \n",
       "7  ...                                            3968338                   \n",
       "8  ...                                            7783323                   \n",
       "9  ...                                                NaN                   \n",
       "\n",
       "   MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander   \n",
       "0                                                NaN           \\\n",
       "1                                                NaN            \n",
       "2                                                NaN            \n",
       "3                                                NaN            \n",
       "4                                                NaN            \n",
       "5                                                NaN            \n",
       "6                                                NaN            \n",
       "7                                              323.0            \n",
       "8                                              610.0            \n",
       "9                                                NaN            \n",
       "\n",
       "   NUM_TESTED_multiracial NUM_PROF_multiracial TOTAL_SCALE_SCORES_multiracial   \n",
       "0                     NaN                  NaN                            NaN  \\\n",
       "1                     NaN                  NaN                            NaN   \n",
       "2                     NaN                  NaN                            NaN   \n",
       "3                     NaN                  NaN                            NaN   \n",
       "4                     NaN                  NaN                            NaN   \n",
       "5                     NaN                  NaN                            NaN   \n",
       "6                     NaN                  NaN                            NaN   \n",
       "7                   847.0                  NaN                         279413   \n",
       "8                   807.0                  509                         494431   \n",
       "9                     NaN                  NaN                            NaN   \n",
       "\n",
       "   MEAN_SCORE_multiracial  NUM_TESTED_white NUM_PROF_white   \n",
       "0                     NaN               NaN            NaN  \\\n",
       "1                     NaN               NaN            NaN   \n",
       "2                     NaN               NaN            NaN   \n",
       "3                     NaN               NaN            NaN   \n",
       "4                     NaN               NaN            NaN   \n",
       "5                     NaN               NaN            NaN   \n",
       "6                     NaN               NaN            NaN   \n",
       "7                   330.0           11234.0            NaN   \n",
       "8                   613.0           11063.0           6383   \n",
       "9                     NaN               NaN            NaN   \n",
       "\n",
       "  TOTAL_SCALE_SCORES_white  MEAN_SCORE_white  \n",
       "0                      NaN               NaN  \n",
       "1                      NaN               NaN  \n",
       "2                      NaN               NaN  \n",
       "3                      NaN               NaN  \n",
       "4                      NaN               NaN  \n",
       "5                      NaN               NaN  \n",
       "6                      NaN               NaN  \n",
       "7                  3642798             324.0  \n",
       "8                  6745329             610.0  \n",
       "9                      NaN               NaN  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the dataframes to save memory\n",
    "del ela_2018, math_2018, science_2018\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "\n",
    "ela_2019 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2019\\Annual EM ELA.csv\"\n",
    ")\n",
    "math_2019 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2019\\Annual EM MATH.csv\"\n",
    ")\n",
    "science_2019 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2019\\Annual EM SCIENCE.csv\"\n",
    ")\n",
    "\n",
    "# testing the function\n",
    "for ds in [ela_2019, math_2019, science_2019]:\n",
    "    sanity_check_entity_cd(ds)\n",
    "\n",
    "    try: \n",
    "        race_df_maker(\n",
    "            ds,\n",
    "            [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "            [\n",
    "                \"Hispanic or Latino\",\n",
    "                \"Black or African American\",\n",
    "                \"American Indian or Alaska Native\",\n",
    "                \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "                \"Multiracial\",\n",
    "                \"White\",\n",
    "            ], keep_cols=Team_9_keep_cols\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(ds.head())\n",
    "        print(ds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [ela_2019, math_2019, science_2019]:\n",
    "\n",
    "    assert 2019 in ds.YEAR.unique()\n",
    "    \n",
    "    new_ds = race_df_maker(\n",
    "        ds,\n",
    "        [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"],  # ENTITY_NAME\n",
    "        [\n",
    "            \"Hispanic or Latino\",\n",
    "            \"Black or African American\",\n",
    "            \"American Indian or Alaska Native\",\n",
    "            \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "            \"Multiracial\",\n",
    "            \"White\",\n",
    "        ],\n",
    "        keep_cols=Team_9_keep_cols,\n",
    "    )\n",
    "\n",
    "    if final_ds is None:\n",
    "\n",
    "        final_ds = new_ds.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        final_ds = pd.concat([final_ds, new_ds], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final_ds: (210576, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sanity checks\n",
    "\n",
    "print(\"Shape of final_ds:\", final_ds.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY_CD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ASSESSMENT_NAME</th>\n",
       "      <th>Subject</th>\n",
       "      <th>NUM_TESTED_hispanic_or_latino</th>\n",
       "      <th>NUM_PROF_hispanic_or_latino</th>\n",
       "      <th>TOTAL_SCALE_SCORES_hispanic_or_latino</th>\n",
       "      <th>MEAN_SCORE_hispanic_or_latino</th>\n",
       "      <th>NUM_TESTED_black_or_african_american</th>\n",
       "      <th>NUM_PROF_black_or_african_american</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>NUM_TESTED_multiracial</th>\n",
       "      <th>NUM_PROF_multiracial</th>\n",
       "      <th>TOTAL_SCALE_SCORES_multiracial</th>\n",
       "      <th>MEAN_SCORE_multiracial</th>\n",
       "      <th>NUM_TESTED_white</th>\n",
       "      <th>NUM_PROF_white</th>\n",
       "      <th>TOTAL_SCALE_SCORES_white</th>\n",
       "      <th>MEAN_SCORE_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210566</th>\n",
       "      <td>6.806011e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210567</th>\n",
       "      <td>6.806011e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210568</th>\n",
       "      <td>6.806011e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210569</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210570</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50</td>\n",
       "      <td>4621</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210571</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210572</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210573</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210574</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50</td>\n",
       "      <td>4621</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210575</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ENTITY_CD    YEAR ASSESSMENT_NAME  Subject   \n",
       "210566  6.806011e+11  2019.0      Science4_8  Science  \\\n",
       "210567  6.806011e+11  2019.0      Science4_8  Science   \n",
       "210568  6.806011e+11  2019.0        Science4  Science   \n",
       "210569  6.808010e+11  2019.0      Science4_8  Science   \n",
       "210570  6.808010e+11  2019.0        Science4  Science   \n",
       "210571  6.808010e+11  2019.0        Science8  Science   \n",
       "210572  6.808010e+11  2019.0        Science8  Science   \n",
       "210573  6.808010e+11  2019.0      Science4_8  Science   \n",
       "210574  6.808010e+11  2019.0        Science4  Science   \n",
       "210575  6.808010e+11  2019.0      Science4_8  Science   \n",
       "\n",
       "        NUM_TESTED_hispanic_or_latino NUM_PROF_hispanic_or_latino   \n",
       "210566                            NaN                         NaN  \\\n",
       "210567                            NaN                         NaN   \n",
       "210568                            NaN                         NaN   \n",
       "210569                            NaN                         NaN   \n",
       "210570                            NaN                         NaN   \n",
       "210571                            NaN                         NaN   \n",
       "210572                            NaN                         NaN   \n",
       "210573                            NaN                         NaN   \n",
       "210574                            NaN                         NaN   \n",
       "210575                            NaN                         NaN   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_hispanic_or_latino  MEAN_SCORE_hispanic_or_latino   \n",
       "210566                                   NaN                            NaN  \\\n",
       "210567                                   NaN                            NaN   \n",
       "210568                                   NaN                            NaN   \n",
       "210569                                   NaN                            NaN   \n",
       "210570                                   NaN                            NaN   \n",
       "210571                                   NaN                            NaN   \n",
       "210572                                   NaN                            NaN   \n",
       "210573                                   NaN                            NaN   \n",
       "210574                                   NaN                            NaN   \n",
       "210575                                   NaN                            NaN   \n",
       "\n",
       "        NUM_TESTED_black_or_african_american   \n",
       "210566                                   NaN  \\\n",
       "210567                                   NaN   \n",
       "210568                                   NaN   \n",
       "210569                                   NaN   \n",
       "210570                                   NaN   \n",
       "210571                                   NaN   \n",
       "210572                                   NaN   \n",
       "210573                                   NaN   \n",
       "210574                                   NaN   \n",
       "210575                                   NaN   \n",
       "\n",
       "       NUM_PROF_black_or_african_american  ...   \n",
       "210566                                NaN  ...  \\\n",
       "210567                                NaN  ...   \n",
       "210568                                NaN  ...   \n",
       "210569                                NaN  ...   \n",
       "210570                                NaN  ...   \n",
       "210571                                NaN  ...   \n",
       "210572                                NaN  ...   \n",
       "210573                                NaN  ...   \n",
       "210574                                NaN  ...   \n",
       "210575                                NaN  ...   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander   \n",
       "210566                                                NaN                  \\\n",
       "210567                                                NaN                   \n",
       "210568                                                NaN                   \n",
       "210569                                                NaN                   \n",
       "210570                                                NaN                   \n",
       "210571                                                NaN                   \n",
       "210572                                                NaN                   \n",
       "210573                                                NaN                   \n",
       "210574                                                NaN                   \n",
       "210575                                                NaN                   \n",
       "\n",
       "        MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander   \n",
       "210566                                                NaN           \\\n",
       "210567                                                NaN            \n",
       "210568                                                NaN            \n",
       "210569                                                NaN            \n",
       "210570                                                NaN            \n",
       "210571                                                NaN            \n",
       "210572                                                NaN            \n",
       "210573                                                NaN            \n",
       "210574                                                NaN            \n",
       "210575                                                NaN            \n",
       "\n",
       "        NUM_TESTED_multiracial NUM_PROF_multiracial   \n",
       "210566                     NaN                  NaN  \\\n",
       "210567                     NaN                  NaN   \n",
       "210568                     NaN                  NaN   \n",
       "210569                     NaN                  NaN   \n",
       "210570                     NaN                  NaN   \n",
       "210571                     NaN                  NaN   \n",
       "210572                     NaN                  NaN   \n",
       "210573                     NaN                  NaN   \n",
       "210574                     NaN                  NaN   \n",
       "210575                     NaN                  NaN   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_multiracial  MEAN_SCORE_multiracial   \n",
       "210566                            NaN                     NaN  \\\n",
       "210567                            NaN                     NaN   \n",
       "210568                            NaN                     NaN   \n",
       "210569                            NaN                     NaN   \n",
       "210570                            NaN                     NaN   \n",
       "210571                            NaN                     NaN   \n",
       "210572                            NaN                     NaN   \n",
       "210573                            NaN                     NaN   \n",
       "210574                            NaN                     NaN   \n",
       "210575                            NaN                     NaN   \n",
       "\n",
       "        NUM_TESTED_white NUM_PROF_white TOTAL_SCALE_SCORES_white   \n",
       "210566               NaN            NaN                      NaN  \\\n",
       "210567               NaN            NaN                      NaN   \n",
       "210568               NaN            NaN                      NaN   \n",
       "210569               NaN            NaN                      NaN   \n",
       "210570              59.0             50                     4621   \n",
       "210571               NaN            NaN                      NaN   \n",
       "210572               NaN            NaN                      NaN   \n",
       "210573               NaN            NaN                      NaN   \n",
       "210574              59.0             50                     4621   \n",
       "210575               NaN            NaN                      NaN   \n",
       "\n",
       "        MEAN_SCORE_white  \n",
       "210566               NaN  \n",
       "210567               NaN  \n",
       "210568               NaN  \n",
       "210569               NaN  \n",
       "210570              78.0  \n",
       "210571               NaN  \n",
       "210572               NaN  \n",
       "210573               NaN  \n",
       "210574              78.0  \n",
       "210575               NaN  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ds.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the dataframes to save memory\n",
    "del ela_2019, math_2019, science_2019\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020 does not exist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericr\\AppData\\Local\\Temp\\ipykernel_36620\\1940774578.py:7: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  math_2021 = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021] ['ELA3' 'ELA4' 'ELA5' 'ELA6' 'ELA7' 'ELA8' 'ELA3_8']\n",
      "'DataFrame' object has no attribute 'MEAN_SCORE'\n",
      "   INSTITUTION_ID     ENTITY_CD         ENTITY_NAME  YEAR ASSESSMENT_NAME   \n",
      "0    8.000001e+11  111111111111  All Public Schools  2021            ELA3  \\\n",
      "1    8.000001e+11  111111111111  All Public Schools  2021            ELA3   \n",
      "2    8.000001e+11  111111111111  All Public Schools  2021            ELA3   \n",
      "3    8.000001e+11  111111111111  All Public Schools  2021            ELA3   \n",
      "4    8.000001e+11  111111111111  All Public Schools  2021            ELA3   \n",
      "\n",
      "                      SUBGROUP_NAME  TOTAL_COUNT  NOT_TESTED  PCT_NOT_TESTED   \n",
      "0                      All Students       192560       99642              52  \\\n",
      "1                            Female        93485       47472              51   \n",
      "2                              Male        99075       52170              53   \n",
      "3  American Indian or Alaska Native         1469         963              66   \n",
      "4         Black or African American        30796       21583              70   \n",
      "\n",
      "   NUM_TESTED  ...  LEVEL1_COUNT LEVEL1_%TESTED LEVEL2_COUNT LEVEL2_%TESTED   \n",
      "0       92918  ...         12736             14        24076             26  \\\n",
      "1       46013  ...          5725             12        11651             25   \n",
      "2       46905  ...          7011             15        12425             26   \n",
      "3         506  ...            84             17          173             34   \n",
      "4        9213  ...          2215             24         3036             33   \n",
      "\n",
      "  LEVEL3_COUNT LEVEL3_%TESTED LEVEL4_COUNT LEVEL4_%TESTED NUM_PROF PER_PROF  \n",
      "0        37709             41        18397             20    56106       60  \n",
      "1        19049             41         9588             21    28637       62  \n",
      "2        18660             40         8809             19    27469       59  \n",
      "3          185             37           64             13      249       49  \n",
      "4         3071             33          891             10     3962       43  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(319420, 21)\n",
      "[2021] ['MATH3' 'MATH4' 'MATH5' 'MATH6' 'MATH7' 'MATH8' 'Combined7Math'\n",
      " 'RegentsMath8' 'RegentsMath7' 'Combined8Math' 'MATH3_8']\n",
      "'DataFrame' object has no attribute 'MEAN_SCORE'\n",
      "   INSTITUTION_ID  ENTITY_CD         ENTITY_NAME  YEAR ASSESSMENT_NAME   \n",
      "0             NaN    4000000  CATTARAUGUS County  2021           MATH3  \\\n",
      "1             NaN    4000000  CATTARAUGUS County  2021           MATH3   \n",
      "2             NaN    4000000  CATTARAUGUS County  2021           MATH3   \n",
      "3             NaN    4000000  CATTARAUGUS County  2021           MATH3   \n",
      "4             NaN    5000000       CAYUGA County  2021           MATH3   \n",
      "\n",
      "                SUBGROUP_NAME  TOTAL_COUNT  NOT_TESTED  PCT_NOT_TESTED   \n",
      "0              In Foster Care          4.0           1            25.0  \\\n",
      "1          Not in Foster Care        862.0         139            16.0   \n",
      "2      Parent in Armed Forces          4.0           0             0.0   \n",
      "3  Parent Not in Armed Forces        862.0         140            16.0   \n",
      "4                All Students        642.0         107            17.0   \n",
      "\n",
      "   NUM_TESTED  ...  LEVEL4_%TESTED LEVEL5_COUNT LEVEL5_%TESTED NUM_PROF   \n",
      "0           3  ...               s          NaN            NaN        s  \\\n",
      "1         723  ...               s          NaN            NaN        s   \n",
      "2           4  ...               s          NaN            NaN        s   \n",
      "3         722  ...               s          NaN            NaN        s   \n",
      "4         535  ...              15          NaN            NaN      232   \n",
      "\n",
      "  PER_PROF TOTAL_EXEMPT NUM_EXEMPT_NTEST PCT_EXEMPT_NTEST NUM_EXEMPT_TEST   \n",
      "0        s          NaN              NaN              NaN             NaN  \\\n",
      "1        s          NaN              NaN              NaN             NaN   \n",
      "2        s          NaN              NaN              NaN             NaN   \n",
      "3        s          NaN              NaN              NaN             NaN   \n",
      "4       43          NaN              NaN              NaN             NaN   \n",
      "\n",
      "  PCT_EXEMPT_TEST  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "(325779, 28)\n",
      "[2021] ['Science4' 'Science8' 'RegentsScience8' 'CombinedScience ' 'Science4_8']\n",
      "'DataFrame' object has no attribute 'MEAN_SCORE'\n",
      "   INSTITUTION_ID     ENTITY_CD         ENTITY_NAME  YEAR ASSESSMENT_NAME   \n",
      "0    8.000001e+11  111111111111  All Public Schools  2021        Science4  \\\n",
      "1    8.000001e+11  111111111111  All Public Schools  2021        Science4   \n",
      "2    8.000001e+11  111111111111  All Public Schools  2021        Science4   \n",
      "3    8.000001e+11  111111111111  All Public Schools  2021        Science4   \n",
      "4    8.000001e+11  111111111111  All Public Schools  2021        Science4   \n",
      "\n",
      "                      SUBGROUP_NAME  TOTAL_COUNT  NOT_TESTED  PCT_NOT_TESTED   \n",
      "0                      All Students     193111.0      102757              53  \\\n",
      "1                            Female      93970.0       49789              53   \n",
      "2                              Male      99141.0       52968              53   \n",
      "3  American Indian or Alaska Native       1400.0         890              64   \n",
      "4         Black or African American      31224.0       22574              72   \n",
      "\n",
      "   NUM_TESTED  ...  LEVEL3_%TESTED LEVEL4_COUNT LEVEL4_%TESTED NUM_PROF   \n",
      "0       90354  ...              35        42977             48    74535  \\\n",
      "1       44181  ...              37        19896             45    36380   \n",
      "2       46173  ...              33        23081             50    38155   \n",
      "3         510  ...              41          175             34      384   \n",
      "4        8650  ...              39         2313             27     5703   \n",
      "\n",
      "  PER_PROF TOTAL_EXEMPT NUM_EXEMPT_NTEST PCT_EXEMPT_NTEST NUM_EXEMPT_TEST   \n",
      "0       82          NaN              NaN              NaN             NaN  \\\n",
      "1       82          NaN              NaN              NaN             NaN   \n",
      "2       83          NaN              NaN              NaN             NaN   \n",
      "3       75          NaN              NaN              NaN             NaN   \n",
      "4       66          NaN              NaN              NaN             NaN   \n",
      "\n",
      "  PCT_EXEMPT_TEST  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "(111678, 26)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 2020 is unobserved\n",
    "\n",
    "# 2021\n",
    "ela_2021 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2021\\Annual EM ELA.csv\"\n",
    ")\n",
    "math_2021 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2021\\Annual EM Math.csv\"\n",
    ")\n",
    "science_2021 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2021\\Annual EM SCIENCE.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# testing the function\n",
    "\n",
    "for ds in [ela_2021, math_2021, science_2021]:\n",
    "    \n",
    "    sanity_check_entity_cd(ds)\n",
    "\n",
    "    try: \n",
    "        race_df_maker(\n",
    "            ds,\n",
    "            [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "            [\n",
    "                \"Hispanic or Latino\",\n",
    "                \"Black or African American\",\n",
    "                \"American Indian or Alaska Native\",\n",
    "                \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "                \"Multiracial\",\n",
    "                \"White\",\n",
    "            ], keep_cols=Team_9_keep_cols\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(ds.YEAR.unique(), ds.ASSESSMENT_NAME.unique())\n",
    "        print(e)\n",
    "        print(ds.head())\n",
    "        print(ds.shape)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['INSTITUTION_ID', 'ENTITY_CD', 'ENTITY_NAME', 'YEAR', 'ASSESSMENT_NAME',\n",
       "       'SUBGROUP_NAME', 'TOTAL_COUNT', 'NOT_TESTED', 'PCT_NOT_TESTED',\n",
       "       'NUM_TESTED', 'PCT_TESTED', 'LEVEL1_COUNT', 'LEVEL1_%TESTED',\n",
       "       'LEVEL2_COUNT', 'LEVEL2_%TESTED', 'LEVEL3_COUNT', 'LEVEL3_%TESTED',\n",
       "       'LEVEL4_COUNT', 'LEVEL4_%TESTED', 'LEVEL5_COUNT', 'LEVEL5_%TESTED',\n",
       "       'NUM_PROF', 'PER_PROF', 'TOTAL_EXEMPT', 'NUM_EXEMPT_NTEST',\n",
       "       'PCT_EXEMPT_NTEST', 'NUM_EXEMPT_TEST', 'PCT_EXEMPT_TEST'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_2021.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">2021 has no mean scores. The message propagates across all 3 subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the dataframes to save memory\n",
    "del ela_2021, math_2021, science_2021\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericr\\AppData\\Local\\Temp\\ipykernel_36620\\591796911.py:6: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  math_2022 = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2022\n",
    "\n",
    "ela_2022 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2022\\Annual EM ELA.csv\"\n",
    ")\n",
    "math_2022 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2022\\Annual EM Math.csv\"\n",
    ")\n",
    "science_2022 = pd.read_csv(\n",
    "    r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\Data-20230420T224029Z-001\\Data\\2022\\Annual EM SCIENCE.csv\"\n",
    ")\n",
    "\n",
    "# testing the function\n",
    "for ds in [ela_2022, math_2022, science_2022]:\n",
    "\n",
    "    sanity_check_entity_cd(ds)\n",
    "\n",
    "    try: \n",
    "        race_df_maker(\n",
    "            ds,\n",
    "            [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"], # ENTITY_NAME\n",
    "            [\n",
    "                \"Hispanic or Latino\",\n",
    "                \"Black or African American\",\n",
    "                \"American Indian or Alaska Native\",\n",
    "                \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "                \"Multiracial\",\n",
    "                \"White\",\n",
    "            ], keep_cols=Team_9_keep_cols\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(ds.head())\n",
    "        print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in [ela_2022, math_2022, science_2022]:\n",
    "\n",
    "    assert 2022 in ds.YEAR.unique()\n",
    "    \n",
    "    new_ds = race_df_maker(\n",
    "        ds,\n",
    "        [\"ENTITY_CD\", \"YEAR\", \"ASSESSMENT_NAME\"],  # ENTITY_NAME\n",
    "        [\n",
    "            \"Hispanic or Latino\",\n",
    "            \"Black or African American\",\n",
    "            \"American Indian or Alaska Native\",\n",
    "            \"Asian or Native Hawaiian/Other Pacific Islander\",\n",
    "            \"Multiracial\",\n",
    "            \"White\",\n",
    "        ],\n",
    "        keep_cols=Team_9_keep_cols,\n",
    "    )\n",
    "\n",
    "    if final_ds is None:\n",
    "\n",
    "        final_ds = new_ds.copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        final_ds = pd.concat([final_ds, new_ds], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final_ds: (339913, 28)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY_CD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ASSESSMENT_NAME</th>\n",
       "      <th>Subject</th>\n",
       "      <th>NUM_TESTED_hispanic_or_latino</th>\n",
       "      <th>NUM_PROF_hispanic_or_latino</th>\n",
       "      <th>TOTAL_SCALE_SCORES_hispanic_or_latino</th>\n",
       "      <th>MEAN_SCORE_hispanic_or_latino</th>\n",
       "      <th>NUM_TESTED_black_or_african_american</th>\n",
       "      <th>NUM_PROF_black_or_african_american</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>NUM_TESTED_multiracial</th>\n",
       "      <th>NUM_PROF_multiracial</th>\n",
       "      <th>TOTAL_SCALE_SCORES_multiracial</th>\n",
       "      <th>MEAN_SCORE_multiracial</th>\n",
       "      <th>NUM_TESTED_white</th>\n",
       "      <th>NUM_PROF_white</th>\n",
       "      <th>TOTAL_SCALE_SCORES_white</th>\n",
       "      <th>MEAN_SCORE_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339903</th>\n",
       "      <td>6.806011e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>63</td>\n",
       "      <td>5795</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339904</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339905</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CombinedScience</td>\n",
       "      <td>CombinedScience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339906</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39</td>\n",
       "      <td>3371</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339907</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339908</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339909</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>CombinedScience</td>\n",
       "      <td>CombinedScience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339910</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339911</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4_8</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339912</th>\n",
       "      <td>6.808010e+11</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Science4</td>\n",
       "      <td>Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>38</td>\n",
       "      <td>3306</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ENTITY_CD    YEAR   ASSESSMENT_NAME          Subject   \n",
       "339903  6.806011e+11  2022.0          Science4          Science  \\\n",
       "339904  6.808010e+11  2022.0          Science8          Science   \n",
       "339905  6.808010e+11  2022.0  CombinedScience   CombinedScience   \n",
       "339906  6.808010e+11  2022.0          Science4          Science   \n",
       "339907  6.808010e+11  2022.0        Science4_8          Science   \n",
       "339908  6.808010e+11  2022.0        Science4_8          Science   \n",
       "339909  6.808010e+11  2022.0  CombinedScience   CombinedScience   \n",
       "339910  6.808010e+11  2022.0          Science8          Science   \n",
       "339911  6.808010e+11  2022.0        Science4_8          Science   \n",
       "339912  6.808010e+11  2022.0          Science4          Science   \n",
       "\n",
       "        NUM_TESTED_hispanic_or_latino NUM_PROF_hispanic_or_latino   \n",
       "339903                            NaN                         NaN  \\\n",
       "339904                            NaN                         NaN   \n",
       "339905                            NaN                         NaN   \n",
       "339906                            NaN                         NaN   \n",
       "339907                            NaN                         NaN   \n",
       "339908                            NaN                         NaN   \n",
       "339909                            NaN                         NaN   \n",
       "339910                            NaN                         NaN   \n",
       "339911                            NaN                         NaN   \n",
       "339912                            NaN                         NaN   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_hispanic_or_latino  MEAN_SCORE_hispanic_or_latino   \n",
       "339903                                   NaN                            NaN  \\\n",
       "339904                                   NaN                            NaN   \n",
       "339905                                   NaN                            NaN   \n",
       "339906                                   NaN                            NaN   \n",
       "339907                                   NaN                            NaN   \n",
       "339908                                   NaN                            NaN   \n",
       "339909                                   NaN                            NaN   \n",
       "339910                                   NaN                            NaN   \n",
       "339911                                   NaN                            NaN   \n",
       "339912                                   NaN                            NaN   \n",
       "\n",
       "        NUM_TESTED_black_or_african_american   \n",
       "339903                                   NaN  \\\n",
       "339904                                   NaN   \n",
       "339905                                   NaN   \n",
       "339906                                   NaN   \n",
       "339907                                   NaN   \n",
       "339908                                   NaN   \n",
       "339909                                   NaN   \n",
       "339910                                   NaN   \n",
       "339911                                   NaN   \n",
       "339912                                   NaN   \n",
       "\n",
       "       NUM_PROF_black_or_african_american  ...   \n",
       "339903                                NaN  ...  \\\n",
       "339904                                NaN  ...   \n",
       "339905                                NaN  ...   \n",
       "339906                                NaN  ...   \n",
       "339907                                NaN  ...   \n",
       "339908                                NaN  ...   \n",
       "339909                                NaN  ...   \n",
       "339910                                NaN  ...   \n",
       "339911                                NaN  ...   \n",
       "339912                                NaN  ...   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander   \n",
       "339903                                                NaN                  \\\n",
       "339904                                                NaN                   \n",
       "339905                                                NaN                   \n",
       "339906                                                NaN                   \n",
       "339907                                                NaN                   \n",
       "339908                                                NaN                   \n",
       "339909                                                NaN                   \n",
       "339910                                                NaN                   \n",
       "339911                                                NaN                   \n",
       "339912                                                NaN                   \n",
       "\n",
       "        MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander   \n",
       "339903                                                NaN           \\\n",
       "339904                                                NaN            \n",
       "339905                                                NaN            \n",
       "339906                                                NaN            \n",
       "339907                                                NaN            \n",
       "339908                                                NaN            \n",
       "339909                                                NaN            \n",
       "339910                                                NaN            \n",
       "339911                                                NaN            \n",
       "339912                                                NaN            \n",
       "\n",
       "        NUM_TESTED_multiracial NUM_PROF_multiracial   \n",
       "339903                     NaN                  NaN  \\\n",
       "339904                     NaN                  NaN   \n",
       "339905                     NaN                  NaN   \n",
       "339906                     NaN                  NaN   \n",
       "339907                     NaN                  NaN   \n",
       "339908                     NaN                  NaN   \n",
       "339909                     NaN                  NaN   \n",
       "339910                     NaN                  NaN   \n",
       "339911                     NaN                  NaN   \n",
       "339912                     NaN                  NaN   \n",
       "\n",
       "       TOTAL_SCALE_SCORES_multiracial  MEAN_SCORE_multiracial   \n",
       "339903                            NaN                     NaN  \\\n",
       "339904                            NaN                     NaN   \n",
       "339905                            NaN                     NaN   \n",
       "339906                            NaN                     NaN   \n",
       "339907                            NaN                     NaN   \n",
       "339908                            NaN                     NaN   \n",
       "339909                            NaN                     NaN   \n",
       "339910                            NaN                     NaN   \n",
       "339911                            NaN                     NaN   \n",
       "339912                            NaN                     NaN   \n",
       "\n",
       "        NUM_TESTED_white NUM_PROF_white TOTAL_SCALE_SCORES_white   \n",
       "339903              70.0             63                     5795  \\\n",
       "339904               NaN            NaN                      NaN   \n",
       "339905               NaN            NaN                      NaN   \n",
       "339906              43.0             39                     3371   \n",
       "339907               NaN            NaN                      NaN   \n",
       "339908               NaN            NaN                      NaN   \n",
       "339909               NaN            NaN                      NaN   \n",
       "339910               NaN            NaN                      NaN   \n",
       "339911               NaN            NaN                      NaN   \n",
       "339912              42.0             38                     3306   \n",
       "\n",
       "        MEAN_SCORE_white  \n",
       "339903              83.0  \n",
       "339904               NaN  \n",
       "339905               NaN  \n",
       "339906              78.0  \n",
       "339907               NaN  \n",
       "339908               NaN  \n",
       "339909               NaN  \n",
       "339910               NaN  \n",
       "339911               NaN  \n",
       "339912              79.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks\n",
    "\n",
    "print(\"Shape of final_ds:\", final_ds.shape)\n",
    "print(\"\")\n",
    "final_ds.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the dataframes to save memory\n",
    "del ela_2022, math_2022, science_2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with Team 9's All Data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\unifying-data-science-2023-project-grupo9\\final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all_data: (2933498, 4)\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print(\"Shape of all_data:\", all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY_CD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Subject</th>\n",
       "      <th>ASSESSMENT_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA3_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY_CD  YEAR Subject ASSESSMENT_NAME\n",
       "0          1  2018     ELA            ELA5\n",
       "1          1  2018     ELA          ELA3_8\n",
       "2          1  2018     ELA            ELA3\n",
       "3          1  2018     ELA            ELA7\n",
       "4          1  2018     ELA            ELA8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENTITY_CD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Subject</th>\n",
       "      <th>ASSESSMENT_NAME</th>\n",
       "      <th>NUM_TESTED_hispanic_or_latino</th>\n",
       "      <th>NUM_PROF_hispanic_or_latino</th>\n",
       "      <th>TOTAL_SCALE_SCORES_hispanic_or_latino</th>\n",
       "      <th>MEAN_SCORE_hispanic_or_latino</th>\n",
       "      <th>NUM_TESTED_black_or_african_american</th>\n",
       "      <th>NUM_PROF_black_or_african_american</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander</th>\n",
       "      <th>NUM_TESTED_multiracial</th>\n",
       "      <th>NUM_PROF_multiracial</th>\n",
       "      <th>TOTAL_SCALE_SCORES_multiracial</th>\n",
       "      <th>MEAN_SCORE_multiracial</th>\n",
       "      <th>NUM_TESTED_white</th>\n",
       "      <th>NUM_PROF_white</th>\n",
       "      <th>TOTAL_SCALE_SCORES_white</th>\n",
       "      <th>MEAN_SCORE_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA5</td>\n",
       "      <td>28234.0</td>\n",
       "      <td>7670</td>\n",
       "      <td>16817855</td>\n",
       "      <td>596.0</td>\n",
       "      <td>14811.0</td>\n",
       "      <td>3749</td>\n",
       "      <td>...</td>\n",
       "      <td>7783323</td>\n",
       "      <td>610.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>509</td>\n",
       "      <td>494431</td>\n",
       "      <td>613.0</td>\n",
       "      <td>11063.0</td>\n",
       "      <td>6383</td>\n",
       "      <td>6745329</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA5</td>\n",
       "      <td>28234.0</td>\n",
       "      <td>7670</td>\n",
       "      <td>16817855</td>\n",
       "      <td>596.0</td>\n",
       "      <td>14811.0</td>\n",
       "      <td>3749</td>\n",
       "      <td>...</td>\n",
       "      <td>7783323</td>\n",
       "      <td>610.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>509</td>\n",
       "      <td>494431</td>\n",
       "      <td>613.0</td>\n",
       "      <td>11063.0</td>\n",
       "      <td>6383</td>\n",
       "      <td>6745329</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA3_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA3_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>ELA</td>\n",
       "      <td>ELA3</td>\n",
       "      <td>28172.0</td>\n",
       "      <td>11285</td>\n",
       "      <td>16769386</td>\n",
       "      <td>595.0</td>\n",
       "      <td>13861.0</td>\n",
       "      <td>5374</td>\n",
       "      <td>...</td>\n",
       "      <td>7375296</td>\n",
       "      <td>610.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>675</td>\n",
       "      <td>572429</td>\n",
       "      <td>611.0</td>\n",
       "      <td>11416.0</td>\n",
       "      <td>7869</td>\n",
       "      <td>6950213</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENTITY_CD  YEAR Subject ASSESSMENT_NAME  NUM_TESTED_hispanic_or_latino   \n",
       "0          1  2018     ELA            ELA5                        28234.0  \\\n",
       "1          1  2018     ELA            ELA5                        28234.0   \n",
       "2          1  2018     ELA          ELA3_8                            NaN   \n",
       "3          1  2018     ELA          ELA3_8                            NaN   \n",
       "4          1  2018     ELA            ELA3                        28172.0   \n",
       "\n",
       "  NUM_PROF_hispanic_or_latino TOTAL_SCALE_SCORES_hispanic_or_latino   \n",
       "0                        7670                              16817855  \\\n",
       "1                        7670                              16817855   \n",
       "2                         NaN                                   NaN   \n",
       "3                         NaN                                   NaN   \n",
       "4                       11285                              16769386   \n",
       "\n",
       "   MEAN_SCORE_hispanic_or_latino  NUM_TESTED_black_or_african_american   \n",
       "0                          596.0                               14811.0  \\\n",
       "1                          596.0                               14811.0   \n",
       "2                            NaN                                   NaN   \n",
       "3                            NaN                                   NaN   \n",
       "4                          595.0                               13861.0   \n",
       "\n",
       "  NUM_PROF_black_or_african_american  ...   \n",
       "0                               3749  ...  \\\n",
       "1                               3749  ...   \n",
       "2                                NaN  ...   \n",
       "3                                NaN  ...   \n",
       "4                               5374  ...   \n",
       "\n",
       "  TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander   \n",
       "0                                            7783323                  \\\n",
       "1                                            7783323                   \n",
       "2                                                NaN                   \n",
       "3                                                NaN                   \n",
       "4                                            7375296                   \n",
       "\n",
       "   MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander   \n",
       "0                                              610.0           \\\n",
       "1                                              610.0            \n",
       "2                                                NaN            \n",
       "3                                                NaN            \n",
       "4                                              610.0            \n",
       "\n",
       "   NUM_TESTED_multiracial NUM_PROF_multiracial TOTAL_SCALE_SCORES_multiracial   \n",
       "0                   807.0                  509                         494431  \\\n",
       "1                   807.0                  509                         494431   \n",
       "2                     NaN                  NaN                            NaN   \n",
       "3                     NaN                  NaN                            NaN   \n",
       "4                   937.0                  675                         572429   \n",
       "\n",
       "   MEAN_SCORE_multiracial  NUM_TESTED_white NUM_PROF_white   \n",
       "0                   613.0           11063.0           6383  \\\n",
       "1                   613.0           11063.0           6383   \n",
       "2                     NaN               NaN            NaN   \n",
       "3                     NaN               NaN            NaN   \n",
       "4                   611.0           11416.0           7869   \n",
       "\n",
       "  TOTAL_SCALE_SCORES_white  MEAN_SCORE_white  \n",
       "0                  6745329             610.0  \n",
       "1                  6745329             610.0  \n",
       "2                      NaN               NaN  \n",
       "3                      NaN               NaN  \n",
       "4                  6950213             609.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.merge(all_data, final_ds, how=\"left\", on=[\"ENTITY_CD\", \"YEAR\", \"Subject\", \"ASSESSMENT_NAME\"])\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENTITY_CD', 'YEAR', 'Subject', 'ASSESSMENT_NAME',\n",
       "       'NUM_TESTED_hispanic_or_latino', 'NUM_PROF_hispanic_or_latino',\n",
       "       'TOTAL_SCALE_SCORES_hispanic_or_latino',\n",
       "       'MEAN_SCORE_hispanic_or_latino', 'NUM_TESTED_black_or_african_american',\n",
       "       'NUM_PROF_black_or_african_american',\n",
       "       'TOTAL_SCALE_SCORES_black_or_african_american',\n",
       "       'MEAN_SCORE_black_or_african_american',\n",
       "       'NUM_TESTED_american_indian_or_alaska_native',\n",
       "       'NUM_PROF_american_indian_or_alaska_native',\n",
       "       'TOTAL_SCALE_SCORES_american_indian_or_alaska_native',\n",
       "       'MEAN_SCORE_american_indian_or_alaska_native',\n",
       "       'NUM_TESTED_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'NUM_PROF_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'TOTAL_SCALE_SCORES_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'MEAN_SCORE_asian_or_native_hawaiian/other_pacific_islander',\n",
       "       'NUM_TESTED_multiracial', 'NUM_PROF_multiracial',\n",
       "       'TOTAL_SCALE_SCORES_multiracial', 'MEAN_SCORE_multiracial',\n",
       "       'NUM_TESTED_white', 'NUM_PROF_white', 'TOTAL_SCALE_SCORES_white',\n",
       "       'MEAN_SCORE_white'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv(r\"C:\\Users\\ericr\\Desktop\\IDS 701 - Unifying Data Science\\uds final project\\unifying-data-science-2023-project-grupo9\\full_data_race.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.isnull().sum()\n",
    "\n",
    "na_cols = full_data.isnull().sum()[full_data.isnull().sum() > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = full_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in na_cols:\n",
    "\n",
    "    test_copy[col].fillna(test_copy.groupby([\"YEAR\",\"ENTITY_CD\",\"Subject\", \"ASSESSMENT_NAME\"])[col].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data\n",
    "\n",
    "full_data[\"MEAN_SCORE\"].fillna(copy_df.groupby([\"YEAR\", \"ENTITY_CD\", \"Subject\"])[\"MEAN_SCORE\"].transform(\"mean\"), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udsV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
